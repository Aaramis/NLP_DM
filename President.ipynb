{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de documents : President\n",
    "\n",
    "Le but de ce TP est de classer des documents textuels... Dans un premier temps, nous allons vérifier le bon fonctionnement des outils sur des données jouets puis appliquer les concepts sur des données réelles.\n",
    "\n",
    "\n",
    "## Conception de la chaine de traitement\n",
    "Pour rappel, une chaine de traitement de documents classique est composée des étapes suivantes:\n",
    "1. Lecture des données et importation\n",
    "    - Dans le cadre de nos TP, nous faisons l'hypothèse que le corpus tient en mémoire... Si ce n'est pas le cas, il faut alors ajouter des structures de données avec des buffers (*data-reader*), bien plus complexes à mettre en place.\n",
    "    - Le plus grand piège concerne l'encodage des données. Dans le TP... Pas (ou peu) de problème. Dans la vraie vie: il faut faire attention à toujours maitriser les formats d'entrée et de sortie.\n",
    "1. Traitement des données brutes paramétrique. Chaque traitement doit être activable ou desactivable + paramétrable si besoin.\n",
    "    - Enlever les informations *inutiles* : chiffre, ponctuations, majuscules, etc... <BR>\n",
    "    **L'utilité dépend de l'application!**\n",
    "    - Segmenter en mots (=*Tokenization*)\n",
    "    - Elimination des stop-words\n",
    "    - Stemming/lemmatisation (racinisation)\n",
    "    - Byte-pair encoding pour trouver les mots composés (e.g. Sorbonne Université, Ville de Paris, Premier Ministre, etc...)\n",
    "1. Traitement des données numériques\n",
    "    - Normalisation *term-frequency* / binarisation\n",
    "    - Normalisation *inverse document frequency*\n",
    "    - Elimination des mots rares, des mots trop fréquents\n",
    "    - Construction de critère de séparabilité pour éliminer des mots etc...\n",
    "1. Apprentissage d'un classifieur\n",
    "    - Choix du type de classifieur\n",
    "    - Réglage des paramètres du classifieur (régularisation, etc...)\n",
    "\n",
    "## Exploitation de la chaine de traitement\n",
    "\n",
    "On appelle cette étape la réalisation d'une campagne d'expériences: c'est le point clé que nous voulons traviller en TAL cette année.\n",
    "1. Il est impossible de tester toutes les combinaisons par rapport aux propositions ci-dessus... Il faut donc en éliminer un certain nombre.\n",
    "    - En discutant avec les experts métiers\n",
    "    - En faisant des tests préliminaires\n",
    "1. Après ce premier filtrage, il faut:\n",
    "    - Choisir une évaluation fiable et pas trop lente (validation croisée, leave-one-out, split apprentissage/test simple)\n",
    "    - Lancer des expériences en grand\n",
    "        - = *grid-search*\n",
    "        - parallèliser sur plusieurs machines\n",
    "        - savoir lancer sur un serveur et se déconnecter\n",
    "1. Collecter et analyser les résultats\n",
    "\n",
    "\n",
    "## Inférence\n",
    "\n",
    "L'inférence est ensuite très classique: la chaine de traitement optimale est apte à traiter de nouveaux documents\n",
    "\n",
    "# Etape 1: charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données:\n",
    "def load_pres(fname):\n",
    "    alltxts = []\n",
    "    alllabs = []\n",
    "    s=codecs.open(fname, 'r','utf-8') # pour régler le codage\n",
    "    while True:\n",
    "        txt = s.readline()\n",
    "        if(len(txt))<5:\n",
    "            break\n",
    "        #\n",
    "        lab = re.sub(r\"<[0-9]*:[0-9]*:(.)>.*\",\"\\\\1\",txt)\n",
    "        txt = re.sub(r\"<[0-9]*:[0-9]*:.>(.*)\",\"\\\\1\",txt)\n",
    "        if lab.count('M') >0:\n",
    "            alllabs.append(-1)\n",
    "        else: \n",
    "            alllabs.append(1)\n",
    "        alltxts.append(txt)\n",
    "    return alltxts,alllabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "class preprocessing():\n",
    "    \"\"\"\n",
    "    All functions related to preprocessing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:   \n",
    "        pass\n",
    "\n",
    "    def do_all(self, text : tuple, my_punc : string = '\\n\\r\\t') -> tuple:\n",
    "        \"\"\"\n",
    "        Apply all the preprocessing function in one loop (to save time) (Except lemmatisation)\n",
    "        \"\"\"\n",
    "        punc = string.punctuation  \n",
    "        punc += my_punc\n",
    "        return [(unicodedata.normalize('NFD'\n",
    "                , re.sub('[0-9]+', ''\n",
    "                , line.lower()\n",
    "                .translate(str.maketrans(punc, ' ' * len(punc)))))\n",
    "                .encode('ascii', 'ignore').decode(\"utf-8\")\n",
    "                .replace(\"  \", \" \")\n",
    "                .strip()\n",
    "                ,pol) for line,pol in text]\n",
    "    \n",
    "    def remove_maj(self, text : tuple) -> tuple :\n",
    "        \"\"\"\n",
    "        Return a tuple of text in lower case\n",
    "        \"\"\"\n",
    "        return [(line.lower(),pol) for line,pol in text]\n",
    "\n",
    "    def remove_punctuation(self, text  : tuple, my_punc : string = '\\n\\r\\t') -> tuple :\n",
    "        \"\"\"\n",
    "        Return a tuple of text without punctuation\n",
    "        \"\"\"\n",
    "        punc = string.punctuation  \n",
    "        punc += my_punc\n",
    "        return [(line.translate(str.maketrans(punc, ' ' * len(punc))),pol) for line, pol in text]\n",
    "\n",
    "    def remove_numbers(self, text : tuple) -> tuple :\n",
    "        \"\"\"\n",
    "        Return a tuple of text without numbers\n",
    "        \"\"\"\n",
    "        return [(re.sub('[0-9]+', '', line),pol) for line,pol in text]\n",
    "\n",
    "    def remove_non_normalized_char(self, text : tuple) -> tuple :\n",
    "        \"\"\"\n",
    "        Return a tuple of text without non normalized char\n",
    "        \"\"\"\n",
    "        return [(unicodedata.normalize('NFD', line).encode('ascii', 'ignore').decode(\"utf-8\"),pol) for line,pol in text]\n",
    "\n",
    "    def get_line(self, text : tuple, sep : str = '\\n', n : int = 0) -> tuple :\n",
    "        \"\"\"\n",
    "        Returns a text list with the n-th line \n",
    "            - sep : string to recognize a new line\n",
    "            - n : Integer of the line (0 = first, -1 = last)\n",
    "        \"\"\"\n",
    "        return [(line.strip().split(sep)[n], pol) for line,pol in text]\n",
    "\n",
    "    def remove_space(self, text : tuple) -> tuple:\n",
    "        \"\"\"\n",
    "        Return a tuple of text without supernumerary space\n",
    "        \"\"\"\n",
    "        return  [(line.replace(\"  \", \" \").strip(), pol) for line,pol in text]\n",
    "\n",
    "    def lemmatisation(self, text : tuple) -> tuple :\n",
    "        \"\"\"\n",
    "        Return a lemmatized list \n",
    "        \"\"\"\n",
    "        # Téléchargez le stemmer français\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('rslp')\n",
    "\n",
    "        # Créez un objet stemmer français\n",
    "        stemmer = FrenchStemmer()\n",
    "        l_words = [(nltk.word_tokenize(line),pol) for line,pol in text]\n",
    "        stemmed_words = [([stemmer.stem(word) for word in line],pol) for line,pol in l_words]\n",
    "        # print(stemmed_words)\n",
    "        return [(\" \".join(line),pol) for line,pol in stemmed_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_path_train = \"./ressources/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "president_path_test = \"./ressources/AFDpresidentutf8/corpus.tache1.test.utf8\"\n",
    "\n",
    "# Parsing\n",
    "palltxts_train, palllabs_train = load_pres(president_path_train)\n",
    "palltxts_test, palllabs_test = load_pres(president_path_test)\n",
    "\n",
    "# Zip in tuple\n",
    "p_train = list(zip(palltxts_train, palllabs_train))\n",
    "p_test = list(zip(palltxts_test, palllabs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movies(path2data): # 1 classe par répertoire\n",
    "    alltxts = [] # init vide\n",
    "    labs = []\n",
    "    cpt = 0\n",
    "    for cl in os.listdir(path2data): # parcours des fichiers d'un répertoire\n",
    "        for f in os.listdir(path2data+cl):\n",
    "            txt = open(path2data+cl+'/'+f).read()\n",
    "            alltxts.append(txt)\n",
    "            labs.append(cpt)\n",
    "        cpt+=1 # chg répertoire = cht classe\n",
    "        \n",
    "    return alltxts,labs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "val.append(len([x for x in palllabs_train if x == 1]))\n",
    "val.append(len([x for x in palllabs_train if x == -1]))\n",
    "label = ['1', '-1']\n",
    "plt.bar(label,val) # Il y a un désequilibre dans notre échantillon, il est fortement probable que -1 soit beaucoup moins bien predit..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation paramétrique du texte\n",
    "\n",
    "Vous devez tester, par exemple, les cas suivants:\n",
    "- transformation en minuscule ou pas\n",
    "- suppression de la ponctuation\n",
    "- transformation des mots entièrement en majuscule en marqueurs spécifiques\n",
    "- suppression des chiffres ou pas\n",
    "- conservation d'une partie du texte seulement (seulement la première ligne = titre, seulement la dernière ligne = résumé, ...)\n",
    "- stemming\n",
    "- ...\n",
    "\n",
    "\n",
    "Vérifier systématiquement sur un exemple ou deux le bon fonctionnement des méthodes sur deux documents (au moins un de chaque classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing preprocessing functions\n",
    "\n",
    "preprocessor = preprocessing()\n",
    "\n",
    "# President\n",
    "two_line = p_train[0:2]\n",
    "two_line[0] = ('   999' + two_line[0][0], two_line[0][1])\n",
    "print(\"Normal text :\")\n",
    "print(two_line)\n",
    "\n",
    "print(\"\\nMinuscule :\")\n",
    "print(preprocessor.remove_maj(two_line))\n",
    "\n",
    "print(\"\\nNumbers :\")\n",
    "print(preprocessor.remove_numbers(two_line))\n",
    "\n",
    "print(\"\\nNormalized char :\")\n",
    "print(preprocessor.remove_non_normalized_char(two_line))\n",
    "\n",
    "print(\"\\npunctuation :\")\n",
    "print(preprocessor.remove_punctuation(two_line))\n",
    "\n",
    "print(\"\\nSpace :\")\n",
    "print(preprocessor.remove_space(two_line))\n",
    "\n",
    "print(\"\\nLemmatisation :\")\n",
    "print(preprocessor.lemmatisation(two_line))\n",
    "\n",
    "print(\"\\nGet line :\") # Here as the separator use is a space it will get the last word\n",
    "print(preprocessor.get_line(two_line, sep = ' ', n = -1))\n",
    "\n",
    "print(\"\\nAll :\")\n",
    "print(preprocessor.do_all(two_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Text\n",
    "\n",
    "# President \n",
    "## Train\n",
    "p_train = preprocessor.do_all(p_train)\n",
    "\n",
    "# p_train = preprocessor.lemmatisation(p_train)\n",
    "\n",
    "## Test\n",
    "p_test = preprocessor.do_all(p_test)\n",
    "# p_test = preprocessor.lemmatisation(p_test)\n",
    "\n",
    "# Movie\n",
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction du vocabulaire\n",
    "\n",
    "Exploration préliminaire des jeux de données.\n",
    "\n",
    "- Quelle est la taille d'origine du vocabulaire?\n",
    "- Que reste-t-il si on ne garde que les 100 mots les plus fréquents? [word cloud]\n",
    "- Quels sont les 100 mots dont la fréquence documentaire est la plus grande? [word cloud] \n",
    "- Quels sont les 100 mots les plus discriminants au sens de odds ratio? [word cloud]\n",
    "- Quelle est la distribution d'apparition des mots (Zipf)\n",
    "- Quels sont les 100 bigrammes/trigrammes les plus fréquents?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import math\n",
    "from scipy import special\n",
    "from gensim import corpora\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "class voc_extracting():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "    def get_size(self, text : tuple) -> int :\n",
    "        \"\"\"\n",
    "        Return the size of a vocabulary\n",
    "        \"\"\"\n",
    "        corpus = [line for line,pol in text]\n",
    "        self.vectorizer.fit_transform(corpus)\n",
    "        return len(self.vectorizer.get_feature_names_out())\n",
    "   \n",
    "    def get_tf_idf(self, text : tuple, n : int = 100) -> list :\n",
    "        \"\"\"\n",
    "        Return the list of n words the most frequent according to TF-IDF\n",
    "        \"\"\"\n",
    "        corpus = [line for line,pol in text]\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "        scores = zip(vectorizer.get_feature_names_out(),\n",
    "                 np.asarray(X.sum(axis=0)).ravel())\n",
    "\n",
    "        sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        return [w[0] for w in sorted_scores[:n]]\n",
    "    \n",
    "    def get_most_freq_word(self, text : tuple, n : int = 100) -> list :\n",
    "        \"\"\"\n",
    "        Return the list of n words the most frequent\n",
    "        \"\"\"\n",
    "        corpus = [line for line,pol in text]\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "        sum_words = X.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "        words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return [w for w,f in words_freq[:n]]\n",
    "\n",
    "    def get_ngram(self, text : tuple, n : int = 100, size : int = 2) -> list :\n",
    "        \"\"\"\n",
    "        Return the list of n words the most frequent associated by group of \"size\" words\n",
    "        \"\"\"\n",
    "        vectorizer = CountVectorizer(ngram_range=(size, size))\n",
    "        corpus = [line for line,pol in text]\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "        sum_words = X.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "        words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return [w for w,f in words_freq[:n]]\n",
    "\n",
    "    def plot_Zipf_distribution(self, text : tuple, n : int = 100) -> list :\n",
    "        \"\"\"\n",
    "        Plot the Zipf distribution of a text according to word frequency\n",
    "        \"\"\"\n",
    "        corpus = [line for line,pol in text]\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "        sum_words = X.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "        words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        freqs = [f for w,f in words_freq]\n",
    "\n",
    "        # Plot\n",
    "        rank = list(np.arange(1,len(freqs) +1))\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.plot(np.log(rank), np.log(freqs))\n",
    "        plt.xlabel('log(Rank)')\n",
    "        plt.ylabel('log(Frequency)')\n",
    "        plt.title('Zipf Distribution')\n",
    "        plt.savefig('./output/zipf_distribution.png', transparent = True)\n",
    "        plt.show()\n",
    "\n",
    "    def word_cloud(self, corpus : list, stop_word : list = None) -> None :\n",
    "        \"\"\"\n",
    "        Display word cloud\n",
    "        \"\"\"\n",
    "        corpus = ' '.join(corpus)\n",
    "        wordcloud = WordCloud(stopwords = stop_word).generate(corpus)\n",
    "        plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    def get_ngram_letter(self, text : tuple, n : int = 100, size : int = 2) -> list :\n",
    "        \"\"\"\n",
    "        Return the list of n word the most frequent associated by group of \"size\" letter\n",
    "        \"\"\"\n",
    "        vectorizer = CountVectorizer(ngram_range=(size, size), analyzer='char_wb', stop_words= ' ')\n",
    "        corpus = [line for line,pol in text]\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "        sum_words = X.sum(axis=0) \n",
    "        words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "        words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return [w.strip() for w,f in words_freq[:n]]\n",
    "\n",
    "    def odd_ratio(self, p : float, q : float) -> int:\n",
    "        \"\"\"\n",
    "        Calculate odd ratios from the frequencies p and q\n",
    "        \"\"\"\n",
    "        if p not in [0,1] and q not in [0,1]:\n",
    "            OR = (p*(1-q)) / (q*(1-p))\n",
    "            return OR\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def get_oddratio(self, text : tuple, n : int = 100) -> list :\n",
    "        \"\"\"\n",
    "        Return  the list of n word the most frequent according to the odd ratio\n",
    "        \"\"\"\n",
    "        vectorizer = CountVectorizer()\n",
    "        corpus = [line for line,pol in text]\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "        #transform\n",
    "\n",
    "        corpus1 = [line for line,pol in text if pol == 1]\n",
    "        corpus2 = [line for line,pol in text if pol == -1]\n",
    "        X_class1 = vectorizer.transform(corpus1)\n",
    "        X_class2 = vectorizer.transform(corpus2)\n",
    "\n",
    "        sum_words1 = X_class1.sum(axis=0)\n",
    "        sum_words2 = X_class2.sum(axis=0)\n",
    "\n",
    "        n_voc = len(vectorizer.vocabulary_)\n",
    "        words_freq1 = [(word, sum_words1[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "        words_freq2 = [(word, sum_words2[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "\n",
    "\n",
    "        odd_ratios = [(word, self.odd_ratio(words_freq1[idx][1]/n_voc, words_freq2[idx][1]/n_voc)) for word, idx in vectorizer.vocabulary_.items()]\n",
    "        odd_ratios = sorted(odd_ratios, key = lambda x: x[1], reverse=True)\n",
    "        return [word for word,freq in odd_ratios[:n]]\n",
    "\n",
    "    def get_doc_freq(self, text : tuple, n : int = 100) -> list :\n",
    "        \"\"\"\n",
    "        Return the list of n words with the highest documentary frequency\n",
    "        \"\"\"\n",
    "        vectorizer = CountVectorizer()\n",
    "        corpus = [line for line,pol in text]\n",
    "        X = vectorizer.fit_transform(corpus)\n",
    "        words_freq = [(word, (np.transpose(X)[idx]!=0).sum(axis=1)[0,0]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "        words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return [word for word, freq in words_freq[:n]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = voc_extracting()\n",
    "\n",
    "print(\"Quelle est la taille d'origine du vocabulaire?\")\n",
    "print(\"Size Voc :\")\n",
    "print(extractor.get_size(p_train))\n",
    "\n",
    "print(\"\\nQue reste-t-il si on ne garde que les 100 mots les plus fréquents? [word cloud]\")\n",
    "print(\"Most frequent words (100)\")\n",
    "most_freq_100 = extractor.get_most_freq_word(p_train, 100)\n",
    "# print(most_freq_100) # Beaucoup de stop word, premier mot intéressant à l'index 35 -> france\n",
    "extractor.word_cloud(most_freq_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Bonus) les 100 mots les plus fréquents selon la fréquence tf-idf? [word cloud]\")\n",
    "print(\"\\nTF-IDF (100) :\")\n",
    "tf_idf_100 = extractor.get_tf_idf(p_train, 100)\n",
    "# print(tf_idf_100) # le mot france est mieux classé, diminution de l'influence des stop word\n",
    "extractor.word_cloud(tf_idf_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quels sont les 100 mots dont la fréquence documentaire est la plus grande? [word cloud]\")\n",
    "print(\"\\nDocumentary frequency (100) :\")\n",
    "doc_freq_100 = extractor.get_doc_freq(p_train, 100)\n",
    "print(doc_freq_100)\n",
    "# print(tf_idf_100) # le mot france est mieux classé, diminution de l'influence des stop word\n",
    "extractor.word_cloud(doc_freq_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quels sont les 100 mots les plus discriminants au sens de odds ratio? [word cloud]\")\n",
    "print(\"\\nODD ratio (100) :\")\n",
    "odd_100 = extractor.get_oddratio(p_train, 100)\n",
    "# print(odd_100)\n",
    "# print(tf_idf_100) # le mot france est mieux classé, diminution de l'influence des stop word\n",
    "extractor.word_cloud(odd_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quelle est la distribution d'apparition des mots (Zipf)\")\n",
    "print(\"\\nZipf dsistribution (100) :\")\n",
    "print(extractor.plot_Zipf_distribution(p_train, 100)) # le mot france est mieux classé, diminution de l'influence des stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quels sont les 100 bigrammes/trigrammes les plus fréquents?\")\n",
    "print(\"\\nNgram 2 (100) :\")\n",
    "ngram_2 = extractor.get_ngram(p_train, 100, 2)\n",
    "ngram_2 = [string.replace(' ', '_') for string in ngram_2]\n",
    "# print(ngram_2)\n",
    "extractor.word_cloud(ngram_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNgram 3 (100) :\")\n",
    "ngram_3 = extractor.get_ngram(p_train, 100, 3)\n",
    "ngram_3 = [string.replace(' ', '_') for string in ngram_3]\n",
    "# print(ngram_3)\n",
    "extractor.word_cloud(ngram_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question qui devient de plus en plus intéressante avec les approches modernes:\n",
    "est-il possible d'extraire des tri-grammes de lettres pour représenter nos documents?\n",
    "\n",
    "Quelle performances attendrent? Quels sont les avantages et les inconvénients d'une telle approche?\n",
    "\n",
    "\n",
    "Les avantages de cette approche comprennent une meilleure précision, une plus grande robustesse et une réduction des problèmes de sur-apprentissage. De plus, le modèle de tri-grammes de lettres est relativement simple à mettre en œuvre et peut être appliqué à une variété de domaines.\n",
    "\n",
    "Les inconvénients de cette approche peuvent inclure une complexité accrue et une plus grande consommation de ressources. De plus, le modèle peut être sujet à des erreurs d'interprétation et des problèmes liés à la taille de l'échantillon.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"st-il possible d'extraire des tri-grammes de lettres pour représenter nos documents?\")\n",
    "print(\"\\nNgram letter 3 (100) :\")\n",
    "lngram_3 = extractor.get_ngram_letter(p_train, 100, 4)\n",
    "print(lngram_3)\n",
    "extractor.word_cloud(lngram_3) # Peut sans doute être utile pour choisir des stop words en masse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles de Machine Learning\n",
    "\n",
    "Avant de lancer de grandes expériences, il faut se construire une base de travail solide en étudiant les questions suivantes:\n",
    "\n",
    "- Combien de temps ça prend d'apprendre un classifieur NB/SVM/RegLog sur ces données en fonction de la taille du vocabulaire?\n",
    "- La validation croisée est-elle nécessaire? Est ce qu'on obtient les mêmes résultats avec un simple *split*?\n",
    "- La validation croisée est-elle stable? A partir de combien de fold (travailler avec différentes graines aléatoires et faire des statistiques basiques)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réponses :\n",
    "\n",
    "Le temps nécessaire pour apprendre un classifieur NB/SVM/RegLog sur des données est proportionnel à la taille du vocabulaire. Plus le vocabulaire est grand, plus le temps de formation sera long. Plus précisément, on peut dire que le temps de formation est approximativement égal à:\n",
    "\n",
    "T = K * V\n",
    "\n",
    "Où T est le temps de formation, K est un facteur constant qui dépend du type de classifieur et du jeu de données, et V est la taille du vocabulaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class model():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.vectorize()\n",
    "\n",
    "    def vectorize(self, lower : bool = True, stripaccents : str = None, stop_words : list = None, gram1 : int = 1, gram2 : int = 1, maxdf :int = 1, mindf : int = 1, maxf : int = any):\n",
    "        # self.vectorizer = TfidfVectorizer(input = 'content'         , lowercase = lower , strip_accents = stripaccents\n",
    "        #                                 , stop_words = stop_words   , ngram_range = (gram1,gram2)   , analyzer = 'word')\n",
    "        self.vectorizer = CountVectorizer(input = 'content'         , lowercase = lower , strip_accents = stripaccents\n",
    "                                        , stop_words = stop_words   , ngram_range = (gram1,gram2)   , analyzer = 'word')\n",
    "\n",
    "    def split_tuple(self, text : tuple):\n",
    "        \"\"\"\n",
    "        Split tuple and return classes with sparse matrice (ready to train)\n",
    "        \"\"\"\n",
    "        classes = [pol for line,pol in text if len(line)]\n",
    "        corpus = [line for line,pol in text if len(line)]\n",
    "        X_train = self.vectorizer.fit_transform(corpus)\n",
    "        return classes, X_train\n",
    "\n",
    "    def mod_nb(self, text : tuple) :\n",
    "        \"\"\"\n",
    "        Naives Bayes\n",
    "        \"\"\"\n",
    "        classes, X_train = self.split_tuple(text)\n",
    "        nb_clf = MultinomialNB()\n",
    "        nb_clf.fit(X_train, classes)\n",
    "        return nb_clf\n",
    "\n",
    "    def mod_logReg(self, text : tuple, state : int = 0, my_solver : str = 'lbfgs', job : int = -1):\n",
    "        \"\"\"\n",
    "        Logistic Regression\n",
    "        \"\"\"\n",
    "        classes, X_train = self.split_tuple(text)\n",
    "        lr_clf = LogisticRegression(random_state = state, solver = my_solver,n_jobs = job, C = 1e-5)\n",
    "        lr_clf.fit(X_train, classes)\n",
    "        return lr_clf\n",
    "\n",
    "    def mod_svm(self, text : tuple, state : int = 0, eps : int = 1e-5):\n",
    "        \"\"\"\n",
    "        Linear SVM\n",
    "        \"\"\"\n",
    "        classes, X_train = self.split_tuple(text)\n",
    "        svm_clf = LinearSVC(random_state = state, C = eps)\n",
    "        svm_clf.fit(X_train, classes)\n",
    "        return svm_clf\n",
    "\n",
    "    def cross_validation(self, mod, text : tuple, fold : int = 100) -> int:\n",
    "        \"\"\"\n",
    "        Return cross validation score\n",
    "        \"\"\" \n",
    "        y, X = self.split_tuple(text)\n",
    "        kf = KFold(n_splits = fold, shuffle = True)\n",
    "        return cross_val_score(mod, X, y, cv = kf)\n",
    "\n",
    "    def mod_predict(self, text : tuple, mod):\n",
    "        \"\"\"\n",
    "        Predict text for all the model given in param\n",
    "        \"\"\"\n",
    "        corpus = [line for line,pol in text if len(line)]\n",
    "        X_test = self.vectorizer.transform(corpus)\n",
    "        pred = mod.predict(X_test)\n",
    "        return pred\n",
    "    \n",
    "    def display_score(self, text : tuple,  pred : list, name : list):\n",
    "        \"\"\"\n",
    "        Print scores\n",
    "        \"\"\"\n",
    "        classes = [pol for line,pol in text if len(line)]\n",
    "        l_score = []\n",
    "        for score,name in zip(pred,name) :\n",
    "            res = accuracy_score(classes, score)\n",
    "            l_score.append(res)\n",
    "            print(f\"Score {name} : {res}\")\n",
    "        return l_score\n",
    "    \n",
    "    def display_bar(self, y_value : list, x_value : list):\n",
    "        plt.bar(x_value, y_value)\n",
    "        # plt.xticks(range(0, len(x_value)), x_value, size=7)\n",
    "        # plt.xticks(rotation='vertical')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "modelizator = model()\n",
    "modelizator.vectorize(lower = True, stop_words = None, maxdf = 1, mindf = 1)\n",
    "\n",
    "pred = []\n",
    "\n",
    "mod_nb = modelizator.mod_nb(p_train)\n",
    "pred.append(modelizator.mod_predict(p_test,mod_nb))\n",
    "\n",
    "mod_logReg = modelizator.mod_logReg(p_train)\n",
    "pred.append(modelizator.mod_predict(p_test,mod_logReg))\n",
    "\n",
    "mod_svm = modelizator.mod_svm(p_train)\n",
    "pred.append(modelizator.mod_predict(p_test,mod_svm))\n",
    "\n",
    "modelizator.display_score(p_test, pred, ['mod_nb', 'mod_logReg', 'mod_svm'])\n",
    "\n",
    "# Accuracy\n",
    "\n",
    "# Score mod_nb : 0.8074685129262724\n",
    "# Score mod_logReg : 0.8925388524710908\n",
    "# Score mod_svm : 0.8925388524710908\n",
    "\n",
    "# F1 Score\n",
    "# Score mod_nb : 0.892045923845709\n",
    "# Score mod_logReg : 0.9432185250048648\n",
    "# Score mod_svm : 0.9432185250048648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "print(modelizator.cross_validation(mod_nb, p_train, 10))\n",
    "print(modelizator.cross_validation(mod_logReg, p_train, 10))\n",
    "print(modelizator.cross_validation(mod_svm, p_train, 10))\n",
    "\n",
    "# Cross validation est plus ou moins stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Première campagne d'expériences\n",
    "\n",
    "Les techniques sur lesquelles nous travaillons étant sujettes au sur-apprentissage: trouver le paramètre de régularisation dans la documentation et optimiser ce paramètre au sens de la métrique qui vous semble la plus appropriée (cf question précédente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_path_train = \"./ressources/AFDpresidentutf8/corpus.tache1.learn.utf8\"\n",
    "president_path_test = \"./ressources/AFDpresidentutf8/corpus.tache1.test.utf8\"\n",
    "\n",
    "# Parsing\n",
    "palltxts_train, palllabs_train = load_pres(president_path_train)\n",
    "palltxts_test, palllabs_test = load_pres(president_path_test)\n",
    "\n",
    "# Zip in tuple\n",
    "p_train = list(zip(palltxts_train, palllabs_train))\n",
    "p_test = list(zip(palltxts_test, palllabs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = preprocessor.do_all(p_train)\n",
    "test = preprocessor.do_all(p_test)\n",
    "\n",
    "X_train = [line for line,pol in train]\n",
    "y_train = [pol for line,pol in train]\n",
    "X_test = [line for line,pol in test]\n",
    "y_test = [pol for line,pol in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Word\n",
    "extractor = voc_extracting()\n",
    "\n",
    "stop1 = extractor.get_most_freq_word(train, 28) # position 29 = france\n",
    "stop2 = extractor.get_tf_idf(train, 26) # position 27 = france\n",
    "stop3 = extractor.get_ngram_letter(train, 100000, 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Baye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pipeline & Gridsearch setup\n",
    "# Pipeline Setup\n",
    "tvc_pipe = Pipeline([\n",
    "                     ('tvec', CountVectorizer()),\n",
    "                    #  ('tvec', TfidfVectorizer()),\n",
    "                     ('mb', LinearSVC())\n",
    "                    ])\n",
    "#fit\n",
    "tvc_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Setting params for bayesian Vectorizer gridsearch\n",
    "tf_params = {\n",
    "    # 'tvec__lowercase': [True],\n",
    "    'tvec__lowercase': ['True'],\n",
    "    # 'tvec__analyzer' : ['word'],\n",
    "    'tvec__analyzer' : ['word'],\n",
    "    # 'tvec__decode_error': ['strict'],\n",
    "    # 'tvec__decode_error': ['strict', 'ignore', 'replace'],\n",
    "    # 'tvec__strip_accents': [None],\n",
    "    'tvec__strip_accents': [None, 'ascii'],\n",
    "    # 'tvec__stop_words': [None],\n",
    "    # 'tvec__stop_words': [None, stop1, stop2, stop3],\n",
    "    # 'tvec__min_df': [0.1],\n",
    "    'tvec__min_df': [0.1,0.2],\n",
    "    # 'tvec__max_df': [0.5],\n",
    "    'tvec__max_df': [0.2,0.5,0.8],\n",
    "    # 'tvec__max_features': [100],\n",
    "    'tvec__max_features': [10, 100 ,1000],\n",
    "    # 'tvec__ngram_range': [(1,4)],\n",
    "    'tvec__ngram_range': [(1, 1), (1,4)],\n",
    "}\n",
    "# Display params we can use\n",
    "# CountVectorizer().get_params().keys()\n",
    "# TfidfVectorizer().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GridSearch for Randomforest\n",
    "score =  'accuracy'  #'accuracy' # 'balanced_accuracy', 'top_k_accuracy', 'average_precision', 'neg_brier_score'\n",
    "tvc_gs = GridSearchCV(tvc_pipe, param_grid=tf_params, scoring =  score, cv = 2, verbose =1, n_jobs = -1)\n",
    "tvc_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Training data\n",
    "print(tvc_gs.score(X_train, y_train))\n",
    "print(tvc_gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = tvc_gs.cv_results_['mean_test_score']\n",
    "params = tvc_gs.cv_results_['params']\n",
    "scores =  [x for x in scores if x > 0 ]\n",
    "scores_R2 = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(score_S, score_R, scores_B)\n",
    "plt.figure(1, figsize=(12, 5))\n",
    "xlab = list(range(len(scores)))\n",
    "# plt.plot(xlab, scores_B, label = 'Naïve Bayes')\n",
    "plt.plot(xlab, scores_R2, label = 'Logistic Regression')\n",
    "# plt.plot(xlab, score_S, label = 'SVM')\n",
    "plt.plot(xlab, scores_S2, label = 'SVM2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylabel('Score moyen')\n",
    "plt.xlabel(\"Combinaisons d'Hyperparamètres\")\n",
    "plt.title('Résultats du GridSearchCV avec un modèle bayésien')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Naïve Baye\n",
    "\n",
    "Best score for Bayesien with countvectorize\n",
    "\n",
    "train = 0.8698726769198614 \\\n",
    "test = 0.8889993373094764\n",
    "\n",
    "{'tvec__analyzer': 'word', \\\n",
    " 'tvec__decode_error': 'strict',  \\\n",
    " 'tvec__lowercase': True, \\\n",
    " 'tvec__max_df': 0.5, \\\n",
    " 'tvec__max_features': 100, \\\n",
    " 'tvec__min_df': 0.1, \\\n",
    " 'tvec__ngram_range': (1, 4), \\\n",
    " 'tvec__stop_words': None, \\\n",
    " 'tvec__strip_accents': None}\n",
    "\n",
    "Best score for Bayesien with TfidfVectorizer\n",
    "\n",
    "train = 0.8689669587027329\\\n",
    "test = 0.8925705029084751\n",
    "\n",
    "{'tvec__analyzer': 'word', \\\n",
    " 'tvec__decode_error': 'strict',  \\\n",
    " 'tvec__lowercase': True, \\\n",
    " 'tvec__max_df': 0.5, \\\n",
    " 'tvec__min_df': 0.1, \\\n",
    " 'tvec__max_features': 100, \\\n",
    " 'tvec__ngram_range': (1, 1), \\\n",
    " 'tvec__stop_words': None, \\\n",
    " 'tvec__strip_accents': None}\n",
    "\n",
    " Le meilleur score pour naïve baye est obtenu avec la fréquence TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = p_train\n",
    "# test = p_test\n",
    "\n",
    "# X_train = [line for line,pol in train]\n",
    "# y_train = [pol for line,pol in train]\n",
    "# X_test = [line for line,pol in test]\n",
    "# y_test = [pol for line,pol in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting params for Logistic Regression gridsearch\n",
    "LG_params = {\n",
    "    # 'C': [1e-5],\n",
    "    'C': [1e-5, 0.001, 0.01, 0.1, 0.5, 0.9],\n",
    "    # 'random_state': [1],\n",
    "    # 'penalty': ['l2'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    # 'solver': ['lbfgs'],\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg' ],\n",
    "    # 'class_weight': [{-1:3.81583145 , 1: 0.57539587 }],\n",
    "    'max_iter': [100,1000] \n",
    "    }\n",
    "# Display params we can use\n",
    "# LogisticRegression().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GridSearch for Logistic Regression\n",
    "model = LogisticRegression()\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), max_df=0.5, min_df=0.08, lowercase=True, max_features=100) # Pas d'influance en changeant avec TF-idf\n",
    "vectors = vectorizer.fit_transform(X_train)\n",
    "score = 'accuracy' # 'balanced_accuracy', 'top_k_accuracy', 'average_precision', 'neg_brier_score'\n",
    "LG_gs = GridSearchCV(model, param_grid=LG_params, cv = 5)# Fitting TVC GS\n",
    "LG_gs.fit(vectors, y_train)# Fitting Randomforest CV GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Training data\n",
    "vectors_test = vectorizer.transform(X_test)\n",
    "print(LG_gs.score(vectors, y_train))\n",
    "print(LG_gs.score(vectors_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG_gs.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "0.8689669587027329 \\\n",
    "0.8925705029084751\n",
    "\n",
    "{'C': 1e-05, 'n_jobs': -1, 'random_state': 1, 'solver': 'lbfgs'}\n",
    "\n",
    "Le score obtenu est légèrement mieux qu'avec les paramètres par défault(0.8925388524710908) mais ce n'est pas impressionant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_ind = le.fit_transform(y_train)\n",
    "recip_freq = len(y_train) / (len(le.classes_) * np.bincount(y_ind).astype(np.float64))\n",
    "weight = recip_freq[le.transform(np.unique(y_train))]\n",
    "print(weight)\n",
    "\n",
    "LSVC_params = {\n",
    "    # 'C':[0.0001],\n",
    "    'C':[0.00001, 0.0001, 0.001],\n",
    "    # 'class_weight':['balanced'], \n",
    "    'class_weight':[None, 'balanced'], \n",
    "    'penalty': ['l2'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    # 'class_weight': [{1:3.81583145 , -1: 0.57539587 }],\n",
    "    # 'loss' : ['hinge'],\n",
    "    'loss' : ['hinge', 'squared_hinge'],\n",
    "    }\n",
    "# Display params we can use\n",
    "LinearSVC().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GridSearch for Logistic Regression\n",
    "model = LinearSVC()\n",
    "vectorizer = CountVectorizer(ngram_range=(1,1), max_df=0.5, min_df=0.08, lowercase=True, max_features=1000) # Pas d'influance en changeant avec TF-idf\n",
    "vectors = vectorizer.fit_transform(X_train)\n",
    "score = 'accuracy' # 'balanced_accuracy', 'top_k_accuracy', 'average_precision', 'neg_brier_score'\n",
    "LSVC_gs = GridSearchCV(model, param_grid=LSVC_params, cv = 5)# Fitting TVC GS\n",
    "LSVC_gs.fit(vectors, y_train)# Fitting Randomforest CV GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Training data\n",
    "vectors_test = vectorizer.transform(X_test)\n",
    "print(LSVC_gs.score(vectors, y_train))\n",
    "print(LSVC_gs.score(vectors_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC_gs.best_params_\n",
    "# sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8689669587027329\\\n",
    "0.8925705029084751\n",
    "\n",
    "{'C': 1e-05, 'class_weight': None}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "Les résultats sont commme notre régression linéaire."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir les paramètres à tester\n",
    "RF_params = {'n_estimators': [10], \n",
    "            # 'n_estimators': [10, 50, 100], \n",
    "            'criterion': ['entropy'],\n",
    "            'max_features': ['sqrt'],\n",
    "            # 'max_features': ['auto', 'sqrt', 'log2'], \n",
    "            'max_depth': [10],\n",
    "            # 'max_depth': [3, 5, 7, 10]\n",
    "            'bootstrap': [True],\n",
    "            'class_weight': [None],\n",
    "            # 'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "            'ccp_alpha': [0.001],\n",
    "            # 'ccp_alpha': [0.001, 0.01, 0.1, 1, 10]\n",
    "    }\n",
    "# Display params we can use\n",
    "RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GridSearch for Random Forest\n",
    "model = RandomForestClassifier()\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words=None) # Pas d'influance en changeant avec TF-idf\n",
    "vectors = vectorizer.fit_transform(X_train)\n",
    "score = 'accuracy' # 'balanced_accuracy', 'top_k_accuracy', 'average_precision', 'neg_brier_score'\n",
    "RF_gs = GridSearchCV(model, param_grid=RF_params, scoring = score,  cv = 5)\n",
    "RF_gs.fit(vectors, y_train)# Fitting Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Training data\n",
    "vectors_test = vectorizer.transform(X_test)\n",
    "print(RF_gs.score(vectors, y_train))\n",
    "print(RF_gs.score(vectors_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat =  RF_gs.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"output/Results_president.txt\", \"a\") \n",
    "\n",
    "file.write(f\"Model : {model}, and Parameters : {RF_gs.best_params_}\\n True Value    Predict Value  Text  \")\n",
    "\n",
    "for text, true_val, pred_val in zip(X_test, y_train, y_hat) :  \n",
    "    file.write(f\"\\n{true_val}   {pred_val}  {text}\") \n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "De toute évidence nous restons bloqué sur le même score que la régression linéaire ou une SVM. Notre désequilibre de départ peut sans doute être lié ou bien nous avons mal fait quelque chose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrage des données\n",
    "\n",
    "Un problème reconnu comme dur dans la communauté est celui de l'équilibrage des classes (*balance* en anglais). Que faire si les données sont à 80, 90 ou 99% dans une des classes?\n",
    "Le problème est dur mais fréquent; les solutions sont multiples mais on peut isoler 3 grandes familles de solution.\n",
    "\n",
    "1. Ré-équilibrer le jeu de données: supprimer des données dans la classe majoritaire et/ou sur-échantilloner la classe minoritaire.<BR>\n",
    "   $\\Rightarrow$ A vous de jouer pour cette technique\n",
    "1. Changer la formulation de la fonction de coût pour pénaliser plus les erreurs dans la classe minoritaire:\n",
    "soit une fonction $\\Delta$ mesurant les écarts entre $f(x_i)$ et $y_i$ \n",
    "$$C = \\sum_i  \\alpha_i \\Delta(f(x_i),y_i), \\qquad \\alpha_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{si } y_i \\in \\text{classe majoritaire}\\\\\n",
    "B>1 & \\text{si } y_i \\in \\text{classe minoritaire}\\\\\n",
    "\\end{array} \\right.$$\n",
    "<BR>\n",
    "   $\\Rightarrow$ Les SVM et d'autres approches sklearn possèdent des arguments pour régler $B$ ou $1/B$... Ces arguments sont utiles mais pas toujours suffisant.\n",
    "1. Courbe ROC et modification du biais. Une fois la fonction $\\hat y = f(x)$ apprise, il est possible de la *bidouiller* a posteriori: si toutes les prédictions $\\hat y$ sont dans une classe, on va introduire $b$ dans $\\hat y = f(x) + b$ et le faire varier jusqu'à ce qu'un des points change de classe. On peut ensuite aller de plus en plus loin.\n",
    "Le calcul de l'ensemble des scores associés à cette approche mène directement à la courbe ROC.\n",
    "\n",
    "**Note:** certains classifieurs sont intrinsèquement plus résistante au problème d'équilibrage, c'est par exemple le cas des techniques de gradient boosting que vous verrez l'an prochain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1\n",
    "# Pour rappel il y a 49890  1 et 7523 -1\n",
    "\n",
    "stock = list(zip(palltxts_train , palllabs_train))\n",
    "plus_stock = [(txt,pol) for txt,pol in stock if pol == 1]\n",
    "minus_stock = [(txt,pol) for txt,pol in stock if pol == -1]\n",
    "reduce_train = plus_stock[:7523] + minus_stock\n",
    "\n",
    "\n",
    "X_train = [line for line,pol in reduce_train]\n",
    "y_train = [pol for line,pol in reduce_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définir les paramètres à tester\n",
    "RF_params = {'n_estimators': [10], \n",
    "            # 'n_estimators': [10, 50, 100], \n",
    "            'criterion': ['entropy'],\n",
    "            # 'max_features': ['sqrt'],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'], \n",
    "            # 'max_depth': [10],\n",
    "            'max_depth': [3, 5, 7, 10],\n",
    "            'bootstrap': [True],\n",
    "            # 'class_weight': [None],\n",
    "            'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "            'ccp_alpha': [0.001],\n",
    "            # 'ccp_alpha': [0.001, 0.01, 0.1, 1, 10]\n",
    "    }\n",
    "# Display params we can use\n",
    "RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GridSearch for Random Forest\n",
    "model = RandomForestClassifier()\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,4), stop_words=stop1) # Pas d'influance en changeant avec TF-idf\n",
    "vectors = vectorizer.fit_transform(X_train)\n",
    "score = 'roc_auc_score' # 'balanced_accuracy', 'top_k_accuracy', 'average_precision', 'neg_brier_score'\n",
    "RF_gs = GridSearchCV(model, param_grid=RF_params, cv = 5)\n",
    "RF_gs.fit(vectors, y_train)# Fitting Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Training data\n",
    "vectors_test = vectorizer.transform(X_test)\n",
    "print(RF_gs.score(vectors, y_train))\n",
    "print(RF_gs.score(vectors_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "Enlever des échantillons nous fait perdre de la précision. Cela ne semble pas être une bonne approche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2 : Gradient Boositng\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_ind = le.fit_transform(y_train)\n",
    "recip_freq = len(y_train) / (len(le.classes_) * np.bincount(y_ind).astype(np.float64))\n",
    "weight = recip_freq[le.transform(np.unique(y_train))]\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train = [line for line,pol in p_train]\n",
    "y_train = [pol for line,pol in p_train]\n",
    "\n",
    "GB_params = {\n",
    "    # 'learning_rate': [0.2],\n",
    "    # 'max_depth': [3],\n",
    "    # 'min_samples_leaf': [3]\n",
    "    # 'learning_rate': [0.1, 0.2, 0.3],\n",
    "    # 'max_depth': [3, 4, 5],\n",
    "    # 'min_samples_leaf': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up GridSearch \n",
    "model = GradientBoostingClassifier()\n",
    "vectorizer = TfidfVectorizer() # Pas d'influance en changeant avec TF-idf\n",
    "vectors = vectorizer.fit_transform(X_train)\n",
    "score = 'accuracy' # 'balanced_accuracy', 'top_k_accuracy', 'average_precision', 'neg_brier_score'\n",
    "GB_gs = GridSearchCV(model, param_grid=GB_params, scoring=score, cv = 2)\n",
    "GB_gs.fit(vectors, y_train)# Fitting Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Training data\n",
    "vectors_test = vectorizer.transform(X_test)\n",
    "print(GB_gs.score(vectors, y_train))\n",
    "print(GB_gs.score(vectors_test, y_test))\n",
    "# 0.9049866754916134\n",
    "# 0.8735733745674104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"output/Results_president.txt\", \"a\") \n",
    "# y_hat =  GB_gs.predict(vectors_test)\n",
    "# file.write(f\"Model : {model}, and Parameters : {GB_gs.best_params_}\\n True Value    Predict Value  Text  \")\n",
    "\n",
    "# for text, true_val, pred_val in zip(X_test, y_train, y_hat) :  \n",
    "#     file.write(f\"\\n{true_val}   {pred_val}  {text}\") \n",
    "    \n",
    "# file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "Le résultat n'est pas très concluant puisque nous descendons en-dessous du score obtenu avec SVM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc5a6fcd42aefd11aead72b01bc4e6842c205ebb69c94514e1be95f4dbf05863"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
