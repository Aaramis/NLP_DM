{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport DM TAL\n",
    "\n",
    "## Analyse des prétraitements\n",
    "\n",
    "### Présidents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse des prétraitements du text c'est fait en faisant varier les paramètres de CountVectorizer et TfidfVectorizer. Les fonctions de prétraitements de text on aussi été recodé mais par volonté de rapidité on a fait varier ces paramètres (excepté la lemmatisation) en faisant appel drectement à gridsearchVC. Voici la liste des paramètres testés (une cross validatio a été fixé à 5):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tf_params = {\n",
    "    'tvec__lowercase': ['True', 'False'],\n",
    "    'tvec__analyzer' : ['word', 'char', 'char_wb'],\n",
    "    'tvec__strip_accents': [None, 'ascii'],\n",
    "    'tvec__stop_words': [None, stop1, stop2, stop3],\n",
    "    'tvec__min_df': [0.1,0.2],\n",
    "    'tvec__max_df': [0.2,0.5,0.9],\n",
    "    'tvec__max_features': [10, 100 ,1000],\n",
    "    'tvec__ngram_range': [(1, 1), (1,3), (1,4)],\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différentes listes de stop word (stop1,2,3) correspond à la liste des stop words optenus à partir de la fréquence documentaire (1), la fréquence tf-idf (2) et les stop word avec un ngram de 1,4 (3). \\\n",
    "\n",
    "#### Modèle Bayesien\n",
    "\n",
    "* Prétraitement sélectionnés :\n",
    "```\n",
    "{'analyzer': 'word', 'lowercase': 'True',  'max_df': 0.9, 'max_features': 100, \n",
    "'min_df': 0.1,  'ngram_range': (1, 1), 'stop_words': None, 'strip_accents': 'ascii'}\n",
    " ```\n",
    "\n",
    "#### Modèle Regression Logisitique\n",
    "\n",
    "* Prétraitement sélectionnés :\n",
    "```\n",
    "{'analyzer': 'word', 'lowercase': 'True', 'max_df': 0.5, 'max_features': 100, 'min_df': 0.1,\n",
    " 'ngram_range': (1, 1), 'stop_words': None, 'strip_accents': 'ascii'}\n",
    "```\n",
    "\n",
    "#### Modèle SVM\n",
    "\n",
    "* Prétraitement sélectionnés :\n",
    "```\n",
    "{'analyzer': 'word', 'lowercase': 'True', 'max_df': 0.5, 'max_features': 1000,\n",
    " 'min_df': 0.1, 'ngram_range': (1, 1), 'stop_words': None, 'strip_accents': 'ascii'}\n",
    "```\n",
    "\n",
    "* Scores :\n",
    "\n",
    "| Données | Bayesien | Regression | SVM |\n",
    "| -------- | -------- | -------- | -------- |\n",
    "| Train | 0.8698 | 0.8709 | 0.8703 |\n",
    "| Test | 0.8884 | 0.8877 | 0.8903 | \n",
    "\n",
    "\n",
    "* Détail des tests :\n",
    "\n",
    "<img src=\"./output/president_pretait_1.png\" alt=\"pretraitement_prez\" />\n",
    "\n",
    "\n",
    "A partir de ces premiers résultats que d'une part les modèles sont relativement proches en terme de performance et que la régression logistique, même si elle semble donner de meilleur résultat sur les données d'entrainement, donne des performances moins bonnes sur les données test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On renouvelle l'experience mais cette fois-ci avec une lemmatisation du text en amont.\n",
    "\n",
    "| Données | Bayesien | Regression | SVM |\n",
    "| -------- | -------- | -------- | -------- |\n",
    "| Train | 0.8694 | 0.8706 | 0.8706 |\n",
    "| Test | 0.8883 | 0.8876 | 0.8908 |\n",
    "\n",
    "La lemmatisation ne semble pas impacter grandement les performances. Maintenant renouvellons les tests mais avec tous les prétraitements (sauf la lemmatisation).\n",
    "\n",
    "| Données | Bayesien | Regression | SVM |\n",
    "| -------- | -------- | -------- | -------- |\n",
    "| Train | 0.8698 | 0.8709 | 0.8703 |\n",
    "| Test | 0.8889 | 0.8877 | 0.8903 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies\n",
    "\n",
    "On a fait varier chaque paramètres en prenant les valeurs par défault pour les aurtes paramètres pour chacun des trois modèles (Naives bayes, Regression et SVM). \\\n",
    "\n",
    "<img src=\"./output/movies_pretrait.png\" alt=\"pretraitement_movies\" />\n",
    "\n",
    "Cette approche est plus économe en terme de temps et permet aussi de se rendre compte plus facilement de l'impact de certains choix sur les performances. On peut notamment voir que gloablement le modèle bayesien est moins efficace pour notre exercice. De meme, le choix du bon grammage aura un impacte significatif sur la performance des modèles."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tunning des paramètres des modèles\n",
    "\n",
    "\n",
    "### Président\n",
    "\n",
    "| Données | Regression | SVM | Random-Forest |\n",
    "| -------- | -------- | -------- | -------- |\n",
    "| Train | 0.87222 | 0.8715 | 0.8689 |\n",
    "| Test | 0.8848 | 0.8882 | 0.8925 |\n",
    "\n",
    "* Regression linéaires :\n",
    "\n",
    "```\n",
    "LG_params = {\n",
    "            'C': [1e-5, 0.001, 0.01, 0.1, 0.5, 0.9],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga', 'lbfgs', 'newton-cg' ],\n",
    "            'class_weight':[None, 'balanced'], \n",
    "            'max_iter': [100,1000] \n",
    "    }\n",
    "```\n",
    "\n",
    "Le score en train augmente mais celui en test diminu. On commence à faire de l'overfitting du le modèle.\n",
    "\n",
    "\n",
    "* SVM :\n",
    "\n",
    "```\n",
    "LSVC_params = {\n",
    "            'C':[0.00001, 0.0001, 0.001],\n",
    "            'class_weight':[None, 'balanced'], \n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'loss' : ['hinge', 'squared_hinge'],\n",
    "    }\n",
    "```\n",
    "\n",
    "Même constat que pour la régression linéaire, une modification des hyperparamètres du modèle enrtaîne un sur-apprentissage.\n",
    "\n",
    "* Random-Forest : \n",
    "\n",
    "```\n",
    "RF_params = {\n",
    "            'n_estimators': [10, 50, 100], \n",
    "            'criterion': ['entropy'],\n",
    "            'max_features': ['auto', 'sqrt', 'log2'], \n",
    "            'max_depth': [3, 5, 7, 10],\n",
    "            'bootstrap': [True],\n",
    "            'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "            'ccp_alpha': [0.001, 0.01, 0.1, 1, 10]\n",
    "    }\n",
    "```\n",
    "Le random forest semble être une technique mieux adaptée. On obtient un résultat plus performant en test que les précédents modèles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies \n",
    "\n",
    "A partir des résultats précédents on a essayé de combiner les différents prétraitements pour améliorer nos performances. \\\n",
    "\n",
    "<img src=\"./output/movies_pretrait2.png\" alt=\"mvs2\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrage des données\n",
    "\n",
    "### Président\n",
    "\n",
    "Le jeu de données initial est désequilibré comme le montre ce graphique : \n",
    "\n",
    "<img src=\"./output/president_classes.png\" alt=\"classes_prez\" />\n",
    "\n",
    "On a environ 85 % des données qui sont de la classe 1. Donc nécessairement, notre modèle sera beaucoup plus à même de trouver d'identifier les élèments de la classe 1 par rapport à la classe -1.\n",
    "On a effectué différents types d'approches pour essayer de combler ce problème :\n",
    "* Ré-équilibrer le jeu de données en supprimant des données dans la classe majoritaire\n",
    "* Attribuer différents poids aux classes.\n",
    "* Utiliser des classifieurs plus robustes face au problème d'équilibrage comme le gradient boosting.\n",
    "\n",
    "\n",
    "Cependant, aucune de ces approches n'a été très convaincantes. Le gradient de boosting obtient effectivement un score plus élévé que les autres classifieurs (0.905944646682807) pour les données d'entrainement mais il est moins performant sur les données de test (0.8654370075841249).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Président\n",
    "\n",
    "Après ce travail d'analyse, nous décidons de partir sur un classifieur de type Random Forest avec les prétraitement suivant :\n",
    "* Pas de majuscules + Pas de ponctuations + Pas de chiffres\n",
    "* Convertorizer : Ngram (1,1) + Pas de stop word\n",
    "* Hyper-paramètre : bootstrap =  True, ccp_alpha = 0.001, class_weight = None, criterion = entropy,max_depth = 10, max_features = sqrt, n_estimators = 10\n",
    "\n",
    "Score :\n",
    "* Train : 0.8689669587027329\n",
    "* Test : 0.8925705029084751\n",
    "\n",
    "L'exercice n'est pas vraiment bien réussi puisque lorsqu'on regarde dans le détail des prédictions en réalité random forest c'est juste contenté de tout classifer comme étant 1..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movies\n",
    "\n",
    "D'après nos résultats les prétraitements les plus optimisés pour chacun de nos modèles testés sont les suivantes : \\\n",
    "* Max NB :  Stemming + Sans stop words + (1,3)gram\n",
    "* Max LR :  Sans stop words + Sans ponctuation + Unigram\n",
    "* Max SVM :  Sans chiffres + (1,3)gram\n",
    "\n",
    "On sélection donne le classifieur SVM avec un prétraitement sans chiffre et un grammage de (1,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
